{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679972cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import numpy as np\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "# Load environment variables from /etc/network_turbo\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "\n",
    "# Set the model path of qwen sft AND sentiment model\n",
    "LM_MODEL = \"august66/qwen2-sft-final\"\n",
    "SENTIMENT_MODEL = \"siebert/sentiment-roberta-large-english\"\n",
    "N_PREFIX_TOKENS = 5\n",
    "\n",
    "\n",
    "#load dataset\n",
    "dataset_test = load_dataset(\"stanfordnlp/imdb\", split=\"test\")\n",
    "def prompt_completion_preprocess(example):\n",
    "    words = example['text'].split()\n",
    "    prompt = ' '.join(words[:N_PREFIX_TOKENS])\n",
    "    completion = ' '.join(words[N_PREFIX_TOKENS:])\n",
    "    return {'prompt': prompt, 'completion': completion}\n",
    "dataset_test = dataset_test.map(prompt_completion_preprocess, remove_columns=['text', 'label'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcbd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "qwen_sft_model = AutoModelForCausalLM.from_pretrained(LM_MODEL)\n",
    "qwen_sft_tokenizer = AutoTokenizer.from_pretrained(LM_MODEL)\n",
    "qwen_sft_tokenizer.padding_side = \"left\"\n",
    "qwen_sft_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "pipe = pipeline(\n",
    "    'text-generation',\n",
    "    model = qwen_sft_model,\n",
    "    tokenizer = qwen_sft_tokenizer,\n",
    "    device_map = 'auto'\n",
    ")\n",
    "prompts = dataset_test['prompt']\n",
    "generated_completions = pipe(\n",
    "    prompts,\n",
    "    max_new_tokens = 128,\n",
    "    do_sample = True,\n",
    "    truncation = True,\n",
    "    padding = True,\n",
    "    top_p = 0.95,\n",
    "    temperature = 1,\n",
    "    num_return_sequences = 2,\n",
    "    batch_size = 128,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538b13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
